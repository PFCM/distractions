{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import rnndatasets.sequentialmnist as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "data, labels = sm.get_data('train', 5000)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoder_forward(input_var, shape, nonlinearity, tied=True, scope=None):\n",
    "    \"\"\"build an autoencoder. `shape` should be a list of\n",
    "    layer sizes. If tied is True, then we will go through shape twice,\n",
    "    once forward and once backwards to build the net. Assumes first entry\n",
    "    of `shape` is the size of the inputs\n",
    "    Returns a list of outputs for each layer, outputs[-1] is the \n",
    "    output of the whole net.\n",
    "    \"\"\"\n",
    "    def affine(name, input_, input_size, layer_size,\n",
    "               transpose_W=False):\n",
    "        if not transpose_W:  # normal feedforward\n",
    "            weights = tf.get_variable(name+'_W', [input_size, layer_size])\n",
    "            bias = tf.get_variable(name+'_b', [layer_size],\n",
    "                                  initializer=tf.zeros_initializer)\n",
    "        else:  # do the weights backwards to make sure we get the same var\n",
    "            weights = tf.get_variable(name+'_W', [layer_size, input_size])\n",
    "            # and give the bias a different name\n",
    "            # somehow it seems that this is not correct to have a fresh\n",
    "            # bias each time\n",
    "            bias = tf.Variable(tf.zeros([layer_size]), name=name+'_other_b')\n",
    "            weights = tf.transpose(weights)\n",
    "        return tf.nn.bias_add(tf.matmul(input_, weights), bias)\n",
    "    \n",
    "    with tf.variable_scope(scope or 'autoencoder') as scope:\n",
    "        # we have to at least go forward once\n",
    "        in_size = shape[0]\n",
    "        layer_input = input_var\n",
    "        net_outs = []\n",
    "        for i, layer_size in enumerate(shape[1:]):\n",
    "            print('{}: ({}, {})'.format(i, layer_size, in_size))\n",
    "            layer_input = nonlinearity(affine(\n",
    "                'layer-{}'.format(i),\n",
    "                layer_input,\n",
    "                in_size,\n",
    "                layer_size))\n",
    "            net_outs.append(layer_input)\n",
    "            in_size = layer_size\n",
    "        if tied:\n",
    "            # do it all again\n",
    "            scope.reuse_variables()\n",
    "            for i, layer_size in reversed(list(enumerate(shape[:-1]))):\n",
    "                print('{}: ({}, {})'.format(i, layer_size, in_size))\n",
    "                layer_input = nonlinearity(affine(\n",
    "                    'layer-{}'.format(i),  # important these match up\n",
    "                    layer_input,\n",
    "                    in_size,\n",
    "                    layer_size,\n",
    "                    True))\n",
    "                in_size = layer_size\n",
    "                net_outs.append(layer_input)\n",
    "        return net_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss_op(net_out, target):\n",
    "    \"\"\"Gets MSE between two guys\"\"\"\n",
    "    return tf.reduce_mean(tf.square(net_out - target))\n",
    "\n",
    "def get_train_op(loss_op, learning_rate, momentum):\n",
    "    \"\"\"Gets an op to minimise everything in the \n",
    "    set of trainable variables\"\"\"\n",
    "    tvars = tf.trainable_variables()\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    grads = opt.compute_gradients(loss_op, tvars)\n",
    "    g_norm = tf.global_norm([grad for grad, var in grads])\n",
    "    return opt.apply_gradients(grads), g_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size):\n",
    "    num_batches = data.shape[0] // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        yield data[i*batch_size:(i+1)*batch_size, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: (100, 784)\n",
      "0: (784, 100)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()  # key\n",
    "\n",
    "# let's do some actual stuff\n",
    "BATCH_SIZE = 100\n",
    "SHAPE = [28*28, 100]\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, name='inputs', shape=[BATCH_SIZE, data.shape[1]])\n",
    "autoenc_outs = autoencoder_forward(\n",
    "    inputs, SHAPE, tf.nn.relu, tied=True)\n",
    "\n",
    "learning_rate = tf.Variable(0.2, name='lr')\n",
    "momentum = tf.Variable(0.8, name='mom')\n",
    "\n",
    "loss_op = get_loss_op(autoenc_outs[-1], inputs)\n",
    "train_op, grad_norm = get_train_op(loss_op, learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...initialising...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# get ready to go\n",
    "sess = tf.InteractiveSession()\n",
    "print('...initialising...')\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: loss 0.2110486873984337, norm 0.008031072579324245\n",
      "Epoch 20: loss 0.2111145278811455, norm 0.008617435591295361\n",
      "Epoch 30: loss 0.2111497575044632, norm 0.008764382489025592\n",
      "Epoch 40: loss 0.21117499113082885, norm 0.008618604075163603\n",
      "Epoch 50: loss 0.21118448317050934, norm 0.008542897757142781\n",
      "Epoch 60: loss 0.211205475628376, norm 0.008577009458094835\n",
      "Epoch 70: loss 0.2111969009041786, norm 0.008334436286240816\n",
      "Epoch 80: loss 0.21118653297424317, norm 0.008174473820254206\n",
      "0.21126 -- 0.00820"
     ]
    }
   ],
   "source": [
    "# actually train\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "sess.run(learning_rate.assign(.1))\n",
    "sess.run(momentum.assign(0.999))\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    np.random.shuffle(data)\n",
    "    num_steps = 0\n",
    "    total_grad_norm = 0\n",
    "    for i, batch in enumerate(batch_iter(data, BATCH_SIZE)):\n",
    "        batch_loss, _, batch_grad_norm = sess.run(\n",
    "             [loss_op, train_op, grad_norm],\n",
    "             {inputs: batch.reshape((BATCH_SIZE, -1))})\n",
    "        total_loss += batch_loss\n",
    "        total_grad_norm += batch_grad_norm\n",
    "        num_steps += 1\n",
    "        if i % 10 == 0:\n",
    "            print('\\r{:.5f} -- {:.5f}'.format(batch_loss, batch_grad_norm), end='')\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('                               '\n",
    "              '\\rEpoch {}: loss {}, norm {}'.format(epoch+1, total_loss/num_steps, total_grad_norm/num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1185927f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJKCAYAAAAx/3HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOXF3d6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113860438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how about plotting a couple\n",
    "ims = sess.run(autoenc_outs[-1], {inputs: data[:BATCH_SIZE, ...].reshape((BATCH_SIZE,-1))})\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(data[0,...].reshape((28,28)), cmap='Greys_r', interpolation='nearest')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(ims[0,...].reshape((28,28)), cmap='Greys_r', interpolation='nearest')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(data[1,...].reshape((28,28)), cmap='Greys_r', interpolation='nearest')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(ims[1,...].reshape((28,28)), cmap='Greys_r', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
