{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from rnndatasets import sequentialmnist as mnist\n",
    "\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we make a network that starts small and grows by splitting its layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def new_collection(name):\n",
    "    old_tvars = tf.trainable_variables()\n",
    "    yield\n",
    "    for var in tf.trainable_variables():\n",
    "        if var not in old_tvars:\n",
    "            tf.add_to_collection(name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affine(input_var, new_size, weights_initialiser=None, bias_initialiser=None, return_weights=False):\n",
    "    input_size = input_var.get_shape()[1].value\n",
    "    \n",
    "    if type(weights_initialiser) == np.ndarray:\n",
    "        weight_shape = None\n",
    "    else:\n",
    "        weight_shape = [input_size, new_size]\n",
    "    \n",
    "    if type(bias_initialiser) == np.ndarray:\n",
    "        bias_shape = None\n",
    "    else:\n",
    "        bias_shape = [new_size]\n",
    "    \n",
    "    weights = tf.get_variable('weights', weight_shape,\n",
    "                             initializer=weights_initialiser)\n",
    "    bias = tf.get_variable('bias', bias_shape,\n",
    "                           initializer=bias_initialiser)\n",
    "    results = tf.nn.bias_add(tf.matmul(input_var, weights), bias)\n",
    "    \n",
    "    if return_weights:\n",
    "        return results, (weights, bias)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initial_net(input_var, output_shape):\n",
    "    return affine(input_var, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iter(data, labels, batch_size):\n",
    "    num_batches = data.shape[0] // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        yield data[i*batch_size:(i+1)*batch_size, ...], labels[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lennox(activations, sess=None):\n",
    "    num_features = activations.get_shape()[1].value\n",
    "    a = tf.get_variable('a', [num_features], initializer=tf.constant_initializer(1.0))\n",
    "    b = tf.get_variable('b', [num_features], initializer=tf.constant_initializer(1.0))\n",
    "    c = tf.get_variable('c', [num_features], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    centered = activations - c\n",
    "    \n",
    "    return tf.select(centered > 0, a * centered, b * centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(net, targets):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(net, targets)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    acc = tf.contrib.metrics.accuracy(tf.cast(tf.argmax(net_out, 1), tf.int32),\n",
    "                                      targets)\n",
    "    return loss, acc\n",
    "\n",
    "def split(session, split_layer, output_layer, layer_in, targets, scope):\n",
    "    # figure out the new value in numpy to keep the graph clean\n",
    "    weights_var, bias_var = split_layer\n",
    "    weights_val, bias_val = session.run([weights_var, bias_var])\n",
    "    u, s, vT = np.linalg.svd(weights_val, full_matrices=False)\n",
    "    print(u.shape, s.shape, vT.shape)\n",
    "    \n",
    "    with tf.variable_scope('model'):\n",
    "        with new_collection('weights'):\n",
    "            with tf.variable_scope(scope + '_split_1'):\n",
    "                hiddens, hh_vars = affine(layer_in, len(s), weights_initialiser=u, bias_initialiser=bias_val,\n",
    "                                                 return_weights=True)\n",
    "            with tf.variable_scope(scope + '_split_2'):\n",
    "                net_out, split_vars = affine(lennox(hiddens), len(s), weights_initialiser=np.dot(np.diag(s), vT),\n",
    "                                             bias_initialiser=tf.constant_initializer(0.0), return_weights=True)\n",
    "        with tf.variable_scope('output', reuse=True):\n",
    "            net_out = affine(lennox(net_out), 10)\n",
    "        \n",
    "    loss, acc = get_metrics(net_out, targets)\n",
    "    \n",
    "    opt = tf.train.AdamOptimizer(0.001)\n",
    "    train_op = opt.minimize(loss)\n",
    "    \n",
    "    return train_op, split_vars, loss, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 784])\n",
    "targets = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    with new_collection('weights'):\n",
    "        net_out, split_layer = affine(inputs, 50, return_weights=True)\n",
    "        with tf.variable_scope('output'):\n",
    "            net_out, output_layer = affine(lennox(net_out), 10, return_weights=True)\n",
    "\n",
    "loss, acc = get_metrics(net_out, targets)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.001)\n",
    "train_op = opt.minimize(loss, var_list=tf.get_collection('weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6) ~~ 0.17306154111588656  (valid: 0.9530248397435898)\n",
      "time to split\n",
      "(784, 50) (50,) (50, 50)\n",
      "['model/split_6_split_1/weights:0', 'model/split_6_split_1/bias:0', 'model/split_6_split_2/a:0', 'model/split_6_split_2/b:0', 'model/split_6_split_2/c:0', 'model/split_6_split_2/weights:0', 'model/split_6_split_2/bias:0', 'beta1_power_1:0', 'beta2_power_1:0', 'model/output/a/Adam_2:0', 'model/output/a/Adam_3:0', 'model/output/b/Adam_2:0', 'model/output/b/Adam_3:0', 'model/output/c/Adam_2:0', 'model/output/c/Adam_3:0', 'model/output/weights/Adam_2:0', 'model/output/weights/Adam_3:0', 'model/output/bias/Adam_2:0', 'model/output/bias/Adam_3:0', 'model/split_6_split_1/weights/Adam:0', 'model/split_6_split_1/weights/Adam_1:0', 'model/split_6_split_1/bias/Adam:0', 'model/split_6_split_1/bias/Adam_1:0', 'model/split_6_split_2/a/Adam:0', 'model/split_6_split_2/a/Adam_1:0', 'model/split_6_split_2/b/Adam:0', 'model/split_6_split_2/b/Adam_1:0', 'model/split_6_split_2/c/Adam:0', 'model/split_6_split_2/c/Adam_1:0', 'model/split_6_split_2/weights/Adam:0', 'model/split_6_split_2/weights/Adam_1:0', 'model/split_6_split_2/bias/Adam:0', 'model/split_6_split_2/bias/Adam_1:0']\n",
      "(7) ~~ 0.19911098412969047  (valid: 0.9537259615384616)\n",
      "time to split\n",
      "(50, 50) (50,) (50, 50)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions 784 and 50 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-27114968275c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m6\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvalid_steps\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\ntime to split'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'split_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0muninits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ff495fd3f583>\u001b[0m in \u001b[0;36msplit\u001b[1;34m(session, split_layer, output_layer, layer_in, targets, scope)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_split_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 hiddens, hh_vars = affine(layer_in, len(s), weights_initialiser=u, bias_initialiser=bias_val,\n\u001b[1;32m---> 19\u001b[1;33m                                                  return_weights=True)\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_split_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 net_out, split_vars = affine(lennox(hiddens), len(s), weights_initialiser=np.dot(np.diag(s), vT),\n",
      "\u001b[1;32m<ipython-input-3-9bfee58863e2>\u001b[0m in \u001b[0;36maffine\u001b[1;34m(input_var, new_size, weights_initialiser, bias_initialiser, return_weights)\u001b[0m\n\u001b[0;32m     16\u001b[0m     bias = tf.get_variable('bias', bias_shape,\n\u001b[0;32m     17\u001b[0m                            initializer=bias_initialiser)\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1350\u001b[0m                                    \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m                                    \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m                                    name=name)\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m \u001b[0msparse_matmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_mat_mul\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   1294\u001b[0m   \"\"\"\n\u001b[0;32m   1295\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[1;32m-> 1296\u001b[1;33m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1297\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                            op_def=op_def)\n\u001b[0m\u001b[0;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2317\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2319\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2320\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2321\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1709\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1710\u001b[0m                          % op.type)\n\u001b[1;32m-> 1711\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1712\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mmatmul_shape\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[0minner_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ma_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m   \u001b[0minner_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose_b\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mb_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m   \u001b[0minner_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mathewpaul1/.pyenv/versions/3.5.1/envs/py3-workspace/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\"\n\u001b[1;32m--> 108\u001b[1;33m                        % (self, other))\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions 784 and 50 are not compatible"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(500):\n",
    "    train, valid, test = mnist.get_iters(batch_size=64, shuffle=True)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_steps = 0\n",
    "    for dbatch, tbatch in train:\n",
    "        dbatch = dbatch.transpose((1, 0, 2))\n",
    "        batch_loss, _ = sess.run([loss, train_op],\n",
    "                                 {inputs: dbatch.reshape((-1, 784)),\n",
    "                                  targets: tbatch})\n",
    "        epoch_loss += batch_loss\n",
    "        epoch_steps += 1\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        valid_loss = 0\n",
    "        valid_steps = 0\n",
    "        for dbatch, tbatch in valid:\n",
    "            dbatch = dbatch.transpose((1, 0, 2))\n",
    "            batch_loss = sess.run(acc,\n",
    "                                 {inputs: dbatch.reshape((-1, 784)),\n",
    "                                  targets: tbatch})\n",
    "            valid_loss += batch_loss\n",
    "            valid_steps += 1\n",
    "            \n",
    "        valid_losses.append(valid_loss/valid_steps)\n",
    "    \n",
    "    \n",
    "    print('\\r({}) ~~ {}  (valid: {})'.format(epoch, epoch_loss/epoch_steps, valid_loss/valid_steps), end='')\n",
    "    losses.append(epoch_loss/epoch_steps)\n",
    "    \n",
    "    if len(valid_losses) > 6 and valid_loss/valid_steps <= valid_losses[-1]:\n",
    "        print('\\ntime to split')\n",
    "        train_op, split_layer, loss, acc = split(sess, split_layer, output_layer, inputs, targets, 'split_{}'.format(epoch))\n",
    "        \n",
    "        uninits = [var for var in tf.all_variables() if not sess.run(tf.is_variable_initialized(var))]\n",
    "        print([var.name for var in uninits])\n",
    "        sess.run([var.initializer for var in uninits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(np.arange(len(valid_losses)) * 1, valid_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
